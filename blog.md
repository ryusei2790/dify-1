# Difyをローカルで動かす：Docker Composeで始めるLLMアプリ開発環境構築

## はじめに
生成AIの波が一気に押し寄せる中、「自分でも本格的なAIアプリを作ってみたい」と思いながら、最初の一歩でつまずいてしまう人は少なくありません。モデル選定、RAG、ワークフロー設計、API連携…やることが多すぎて、何から触ればいいのか分からない。そんな悩みを解決してくれるのが、オープンソースのLLMアプリ開発プラットフォームであるDifyです。

クラウドを使わずとも、あなたのPC上に本格的なAI開発環境をまるごと構築できるのがDifyの魅力。Docker Composeさえあれば、RAGもエージェントもワークフローも、すべてローカルで完結させることができます。

この記事では、その「ローカルDify環境」を最短ルートで立ち上げる方法をまとめました。初めての方でも迷わず進められるよう、構成の仕組みからセットアップのコツまでやさしく整理しています。ここから、AIアプリ開発の世界がぐっと身近になるはずです。

私は現在、aniumaでインターンをさせてもらっている　ryusei　です。

師匠から学んだことや自学したものをアウトプットしていく場として今は技術ブログ的な感じで書かせていただいています。
最近ではAIの発展が著しいので自分も波に負けない人材になるべく健闘中です。

###　それでは実際に今日はDifyをローカルに立てて自分だけのAIを実装してみます。

AIアプリケーション開発に興味があるけれど、どこから始めればいいかわからない。そんな方にとって、Difyは理想的な開発プラットフォームです。DifyはオープンソースのLLMアプリケーション開発プラットフォームで、直感的なインターフェースでワークフロー構築、RAG（Retrieval-Augmented Generation）パイプライン、エージェント機能を実現できます。

クラウド版も提供されていますが、ローカル環境で動かすメリットは大きいです。開発・検証環境として自由に実験でき、プライバシーを重視したユースケースにも対応できます。また、クラウドのコストを気にせず、思う存分試すことができます。

この記事では、Docker Composeを使ってDifyをローカル環境に構築する手順を解説します。30分程度でセットアップが完了し、アーキテクチャの理解も深められる内容になっています。実際に手を動かしながら読み進めていただければ、あなたもすぐにLLMアプリ開発を始められます。

## Difyのアーキテクチャ概観

セットアップに入る前に、Difyがどのような構成で動いているのかを理解しましょう。Difyは複数のサービスが連携するマイクロサービスアーキテクチャを採用しています。

### 主要サービスの役割

| サービス | 役割 | 技術スタック |
|---------|------|-------------|
| **api** | バックエンドAPI | Python Flask |
| **web** | フロントエンド（管理画面） | Next.js 15 |
| **worker** | 非同期タスク処理 | Celery |
| **worker_beat** | スケジュール管理 | Celery Beat |
| **db_postgres** | メインデータベース | PostgreSQL 15 |
| **redis** | キャッシュ＋メッセージブローカー | Redis 6 |
| **weaviate** | ベクターデータベース | Weaviate |
| **nginx** | リバースプロキシ | Nginx |

それぞれのサービスには明確な役割があります。apiサービスはビジネスロジックを処理し、webサービスはユーザーインターフェースを提供します。workerは重い処理をバックグラウンドで実行するため、ユーザーは待たされることなくレスポンスを受け取れます。db_postgresにはアカウント情報やアプリケーション設定が保存され、redisはキャッシュとCeleryのメッセージングに使われます。weaviateはRAG機能に必須のベクターデータベースで、テキストをベクトルに変換して意味検索を実現します。
ここら辺の詳しい内容は今回あまり必要ないのでおいおい自分も理解して使用できるようになればと思っています。

### サービス間の通信フロー

```
ユーザー → Nginx（ポート80）
           ↓
       ┌──────┴──────┐
       ↓             ↓
     Web          API（Flask）
  （Next.js）        ↓
                  ┌──┴──┐
                  ↓     ↓
             PostgreSQL Redis ← Worker（Celery）
                         ↓
                    Weaviate（RAG検索時）
```

ユーザーからのリクエストは、まずNginxが受け付けます。NginxはURLパスに応じて、webサービス（管理画面）またはapiサービス（バックエンドAPI）にリクエストを振り分けます。APIは必要に応じてPostgreSQLからデータを取得し、重い処理はRedis経由でWorkerに委譲します。RAG機能を使う場合は、Weaviateから関連する文書を検索して、LLMへのプロンプトに含めます。

## セットアップ手順

それでは、実際にDifyをローカル環境に構築していきましょう。

### 前提条件

- Docker Desktop がインストール済み
- メモリ 8GB 以上推奨
- ディスク空き容量 10GB 以上

### ステップ1: リポジトリ取得

まず、GitHubからDifyのリポジトリをクローンします。

```bash
git clone https://github.com/langgenius/dify.git
cd dify/docker
```

### ステップ2: 環境ファイル準備

Difyの設定は`.env`ファイルで一元管理されています。サンプルファイルをコピーして、環境ファイルを作成します。

```bash
cp .env.example .env
```

初回セットアップでは、デフォルト設定のまま起動できます。ただし、本番環境で使う場合は、必ず以下の設定を変更してください。

- `SECRET_KEY`: セッション暗号化キー（`openssl rand -base64 42`で生成）
- `DB_PASSWORD`: PostgreSQLのパスワード（デフォルト: difyai123456）
- `REDIS_PASSWORD`: Redisのパスワード（デフォルト: difyai123456）

### ステップ3: Docker Compose起動

環境ファイルの準備ができたら、Docker Composeでサービスを起動します。

```bash
docker compose up -d
```

`-d`フラグを付けることで、バックグラウンドで起動します。初回は、Dockerイメージのダウンロードに5〜10分程度かかります。
基本的にはこれで環境を立ち上げてくれるので必要なシークレットキーを設定したら自動でDifyを使用できるようになります。

### ステップ4: 起動確認

全てのサービスが正常に起動しているか確認します。

```bash
docker compose ps
```

**期待される出力:**

```
NAME                     STATUS
docker-api-1             Up
docker-db_postgres-1     Up (healthy)
docker-nginx-1           Up
docker-plugin_daemon-1   Up
docker-redis-1           Up (healthy)
docker-sandbox-1         Up (healthy)
docker-ssrf_proxy-1      Up
docker-weaviate-1        Up
docker-web-1             Up
docker-worker-1          Up
docker-worker_beat-1     Up
```

全てのサービスのSTATUSが`Up`または`Up (healthy)`になっていれば成功です。もし一部のサービスが起動していない場合は、ログを確認してください。

```bash
docker compose logs api
```

### ステップ5: ブラウザアクセスと初期設定

ブラウザで`http://localhost`にアクセスすると、初回セットアップ画面が表示されます。

**管理者アカウント作成:**

1. 言語を選択（日本語またはEnglish）
2. 以下の情報を入力
   - メールアドレス（例: admin@example.com）
   - 名前（例: Admin User）
   - パスワード（8文字以上）
   - パスワード確認
3. 「続ける」をクリック

アカウント作成が完了すると、自動的にDifyのダッシュボードにログインします。ダッシュボードには以下のメニューが表示されます。

- **スタジオ**: アプリケーション作成画面
- **ナレッジ**: RAGデータソース管理
- **ツール**: 外部ツール連携
- **設定**: システム設定

これでセットアップは完了です。

## アーキテクチャ深掘り

ここからは、Difyのアーキテクチャをさらに深く理解していきましょう。

### Nginxのリバースプロキシ機能

なぜNginxが必要なのでしょうか。それは、ユーザーからのリクエストを適切なサービスに振り分けるためです。

Nginxは、ポート80で全てのHTTPリクエストを受け付け、URLパスに応じて以下のようにルーティングします。

- `/console/api/*` → api:5001（管理画面のAPI）
- `/api/*` → api:5001（サービスAPI）
- `/v1/*` → api:5001（OpenAI互換API）
- `/files/*` → api:5001（ファイル配信）
- `/` → web:3000（フロントエンド）

この仕組みにより、ユーザーは単一のURLからDifyのすべての機能にアクセスできます。また、本番環境ではNginxがSSL終端を担い、HTTPS通信を実現します。静的ファイルの配信も最適化されるため、パフォーマンスの向上にも寄与します。

### Celeryワーカーの非同期処理

LLMアプリケーションでは、文書の解析や大量のLLM API呼び出しなど、時間のかかる処理が頻繁に発生します。これらをリクエストごとに同期処理すると、ユーザーは長時間待たされてしまいます。

そこでDifyは、Celeryという非同期タスクキューシステムを採用しています。重い処理はRedisのキューに登録され、Workerがバックグラウンドで順次処理します。これにより、ユーザーはすぐにレスポンスを受け取り、処理の完了を待つことができます。

`worker_beat`は、Celery Beatスケジューラーで、定期的なタスク（例: データのクリーンアップ、統計情報の集計）を管理します。これにより、システムの保守が自動化されます。

### ベクターDBの役割と選択肢

RAG（Retrieval-Augmented Generation）は、LLMに外部知識を与える重要な技術です。ユーザーがアップロードした文書をベクトル化して保存し、質問に関連する部分を検索してLLMに渡します。

Difyはデフォルトで**Weaviate**をベクターデータベースとして使用しています。Weaviateは、意味検索（セマンティックサーチ）に特化したデータベースで、テキストを高次元のベクトルに変換して保存します。質問が来ると、質問もベクトル化して、最も近いベクトルを持つ文書を高速に検索します。

ただし、Difyは20種類以上のベクターデータベースに対応しています。`.env`ファイルの`VECTOR_STORE`変数を変更することで、以下のような選択肢から選べます。

- **Qdrant**: 高速で軽量、Rustで実装
- **Milvus**: 大規模データに強い、エンタープライズ向け
- **pgvector**: PostgreSQLの拡張、既存のDBと統合しやすい
- **Chroma**: シンプルで使いやすい、開発向け

各データベースには特性があるため、用途に応じて選択できる柔軟性があります。

### Dockerの設定カスタマイズ

`.env`ファイルには、450以上の設定項目が用意されています。ここでは、特に重要なカスタマイズポイントを紹介します。

**ポート番号の変更:**

デフォルトではNginxがポート80でリッスンしますが、他のサービスと競合する場合は変更できます。

```bash
EXPOSE_NGINX_PORT=8080
```

変更後、`docker compose up -d`で再起動すると、`http://localhost:8080`でアクセスできるようになります。

**ベクターデータベースの切り替え:**

```bash
VECTOR_STORE=qdrant
```

この設定を変更すると、Weaviateの代わりにQdrantが起動します。ただし、既存のデータは移行されないため、データベース変更時は注意が必要です。

**データベースの選択:**

PostgreSQLの代わりにMySQLを使うこともできます。

```bash
DB_TYPE=mysql
```

**本番環境への移行時の注意点:**

本番環境でDifyを運用する場合、以下の設定を必ず変更してください。

- `SECRET_KEY`: 強力なランダムキーを生成（`openssl rand -base64 42`）
- `DB_PASSWORD`: 推測困難なパスワードに変更
- `REDIS_PASSWORD`: 推測困難なパスワードに変更
- `NGINX_HTTPS_ENABLED=true`: HTTPSを有効化
- `LOG_LEVEL=WARNING`: ログレベルを本番向けに調整

詳細な環境変数の説明は、[docker/.env.example](docker/.env.example)を参照してください。

## よくあるトラブルと対処法

セットアップ中に遭遇しやすい問題と、その解決方法を紹介します。

### 502 Bad Gateway エラー

**原因:** APIサーバーがまだ起動中です。Flaskアプリケーションの起動には1〜2分かかることがあります。

**対処法:**

```bash
docker compose logs api
```

ログに`Listening at: http://0.0.0.0:5001`と表示されれば、起動完了です。それまでブラウザをリロードして待ちましょう。

### ポート80が使用中

**原因:** Apache、既存のNginx、他のWebサーバーがポート80を占有しています。

**対処法:**

`.env`ファイルでポート番号を変更します。

```bash
EXPOSE_NGINX_PORT=8080
```

変更後、`docker compose up -d`で再起動し、`http://localhost:8080`でアクセスしてください。

### コンテナが起動しない

**原因:** メモリ不足、またはDockerのリソース制限に引っかかっています。

**対処法:**

Docker Desktopの設定で、割り当てメモリを8GB以上に増やしてください。また、不要なコンテナを停止します。

```bash
docker ps -a
docker stop <container_id>
```

ディスク容量が不足している場合は、以下のコマンドで不要なイメージやボリュームを削除します。

```bash
docker system prune
```

### データベース接続エラー

**原因:** PostgreSQLが`healthy`ステータスになる前に、APIが起動しようとしています。

**対処法:**

APIサービスを再起動します。

```bash
docker compose restart api
```

データベースのログを確認して、エラーがないか確認してください。

```bash
docker compose logs db_postgres
```

## 次のステップ

Difyの環境が整ったら、さっそくアプリケーションを作ってみましょう。

### 1. LLMプロバイダーの設定

ダッシュボードから「設定」→「モデルプロバイダー」を開き、使いたいLLMのAPIキーを登録します。対応しているプロバイダーは以下の通りです。

- OpenAI（GPT-4、GPT-3.5など）
- Anthropic（Claude）
- Azure OpenAI
- Google（Gemini）
- ローカルLLM（Ollama、LM Studioなど）

### 2. 最初のアプリケーション作成

「スタジオ」→「空のアプリを作成」から、簡単なチャットボットを作ってみましょう。

1. アプリタイプで「チャットアシスタント」を選択
2. プロンプトを入力（例: 「あなたは親切なアシスタントです」）
3. モデルを選択（例: gpt-3.5-turbo）
4. 「公開」をクリック
5. 右側のプレビューでテスト

### 3. RAGアプリの構築

「ナレッジ」→「新規作成」から、自分の文書を取り込んでRAGアプリを作成できます。

1. PDFやテキストファイルをアップロード
2. 文書が自動的に解析され、ベクトル化される
3. アプリケーションにナレッジを連携
4. 文書の内容に基づいた回答ができるようになる

### 参考リンク

- [Dify公式ドキュメント](https://docs.dify.ai/)
- [GitHub リポジトリ](https://github.com/langgenius/dify)
- [Discord コミュニティ](https://discord.gg/dify)
- [詳細なセットアップガイド](LOCAL_SETUP_GUIDE.md)

## まとめ

この記事では、DifyをDocker Composeでローカル環境に構築する手順を解説しました。Difyはマイクロサービスアーキテクチャを採用しており、各サービスが明確な役割を持っています。Nginxがリクエストをルーティングし、Celeryが重い処理をバックグラウンドで実行し、Weaviateが意味検索を実現します。

Docker Composeを使えば、これらの複雑なサービスを簡単に起動できます。環境変数をカスタマイズすることで、ポート番号の変更やベクターデータベースの切り替えも柔軟に行えます。

もしセットアップ中に問題が発生した場合は、[LOCAL_SETUP_GUIDE.md](LOCAL_SETUP_GUIDE.md)により詳細なトラブルシューティング情報が記載されています。また、公式ドキュメントやコミュニティも活用してください。

これで、あなたもLLMアプリケーション開発の第一歩を踏み出せました。Difyの豊富な機能を探索し、自分だけのAIアプリケーションを作ってみてください。
